{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topicData():\n",
    "    topic = pd.read_csv('../training_data/topic.csv',header=None).values.T[0]\n",
    "    return topic\n",
    "\n",
    "def eventData():\n",
    "    event = pd.read_csv('../training_data/event.csv',header=None).values.T[0]\n",
    "    return event\n",
    "\n",
    "def callData():\n",
    "    call = pd.read_csv('../training_data/call.csv',header=None).values.T[0]\n",
    "    return call\n",
    "\n",
    "def waterData():\n",
    "    water = pd.read_csv('../training_data/water.csv',header=None).values.T[0]\n",
    "    return water\n",
    "\n",
    "def visitorData():\n",
    "    visitor = pd.read_csv('../training_data/visitor.csv',header=None).values.T[0]\n",
    "    return visitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 English vocab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "def getVocabList():\n",
    "    vocabs = pd.read_csv('../vocab2.csv')\n",
    "    vocabs['number'] = vocabs.index + 1\n",
    "    vocabs['word'] = vocabs['0']\n",
    "    del vocabs['0']\n",
    "    return vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223737, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>aah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>aal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aalii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>aam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>aani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>aardvark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>aardwolf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      word\n",
       "0       1         a\n",
       "1       2        aa\n",
       "2       3       aaa\n",
       "3       4       aah\n",
       "4       5       aal\n",
       "5       6     aalii\n",
       "6       7       aam\n",
       "7       8      aani\n",
       "8       9  aardvark\n",
       "9      10  aardwolf"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(getVocabList().shape)\n",
    "getVocabList()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Process text to feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "def processText(email_contents):\n",
    "    #load vocab\n",
    "    vocabList = getVocabList()\n",
    "    \n",
    "    # ----- Process Email------\n",
    "    # Lower Case\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    strip_all_html = re.compile('[>,<,<*>]') \n",
    "    email_contents = re.sub(strip_all_html, '', email_contents)\n",
    "    strip_all_html2 = re.compile('\\s') # \\s is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
    "    email_contents = re.sub(strip_all_html2, ' ', email_contents)\n",
    "    \n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    hundle_number = re.compile('\\d+')\n",
    "    email_contents = re.sub(hundle_number, 'number', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    hundle_url = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    email_contents = re.sub(hundle_url, 'httpaddr', email_contents)\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    hundle_email = re.compile('[\\w\\.-]+@[\\w\\.-]+')\n",
    "    email_contents = re.sub(hundle_email, 'emailaddr', email_contents)\n",
    "\n",
    "    # Handle $ sign\n",
    "    hundle_dollar = re.compile('[$]+')\n",
    "    email_contents = re.sub(hundle_dollar, 'dollar', email_contents)\n",
    "    \n",
    "    # Remove any non alphanumeric characters\n",
    "    non_cha_alp = re.compile(\"[^a-zA-Z0-9]+\")\n",
    "    email_contents = re.sub(non_cha_alp, ' ', email_contents)\n",
    "    \n",
    "    # ------- Stem words -------    \n",
    "    words = [stem(word) for word in email_contents.split(\" \") if len(word) > 0]\n",
    "    \n",
    "    # convert to number in vocab\n",
    "    word_indices = []\n",
    "    for w in words:\n",
    "        match = sum(vocabList['word'] == w)\n",
    "        if(match>0):\n",
    "            word_indices.append(vocabList.loc[(vocabList['word'] == w),'number'].astype(int).values[0])\n",
    "    \n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[171879, 178439, 196596, 161447, 118766, 18448]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processText(\"Send someone to repair my bathroom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textFeatures(word_indices):\n",
    "    vocabList = getVocabList()\n",
    "    features = vocabList['number'].astype(int).isin(word_indices) + 0\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFeatures(processText(\"Send someone to repair my bathroom.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Initial features vector for each menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getInitialFeatureVectoc():\n",
    "    topic = topicData()\n",
    "    event = eventData()\n",
    "    call = callData()\n",
    "    water = waterData()\n",
    "    visitor = visitorData()\n",
    "    # Topic\n",
    "    topic_features = np.zeros(len(getVocabList()))\n",
    "    for i in range(len(topic)):\n",
    "        topic_features = topic_features + textFeatures(processText(topic[i]))\n",
    "\n",
    "    # Event\n",
    "    event_features = np.zeros(len(getVocabList()))\n",
    "    for i in range(len(event)):\n",
    "        event_features = event_features + textFeatures(processText(event[i]))\n",
    "    \n",
    "    # Call     \n",
    "    call_features = np.zeros(len(getVocabList()))\n",
    "    for i in range(len(call)):\n",
    "        call_features = call_features + textFeatures(processText(call[i]))\n",
    "    \n",
    "    # Water\n",
    "    water_features = np.zeros(len(getVocabList()))\n",
    "    for i in range(len(water)):\n",
    "        water_features = water_features + textFeatures(processText(water[i]))\n",
    "    \n",
    "    # Visitor\n",
    "    visitor_features = np.zeros(len(getVocabList()))\n",
    "    for i in range(len(visitor)):\n",
    "        visitor_features = visitor_features + textFeatures(processText(visitor[i]))\n",
    "    \n",
    "    topic_features = (topic_features >= 1).astype(int)\n",
    "    event_features = (event_features >= 1).astype(int)\n",
    "    call_features = (call_features >= 1).astype(int)\n",
    "    water_features = (water_features >= 1).astype(int)\n",
    "    visitor_features = (visitor_features >= 1).astype(int)\n",
    "    \n",
    "    return np.array([topic_features, event_features, call_features, water_features, visitor_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_features = getInitialFeatureVectoc()\n",
    "initial_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Compare similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "def most_similarity(initial_features,text_feature):\n",
    "    A = np.vstack((initial_features,text_feature))\n",
    "    A_sparse = sparse.csr_matrix(A)\n",
    "    similarities = cosine_similarity(A_sparse)\n",
    "    print('pairwise dense output:\\n {}\\n'.format(similarities))\n",
    "\n",
    "    text_vs_initial = similarities[similarities.shape[0]-1,0:similarities.shape[1]-1]\n",
    "    prob_of_menu = np.max(text_vs_initial)\n",
    "    menu = np.argmax(text_vs_initial)\n",
    "    if(prob_of_menu < 0.3):\n",
    "        return \"other\"\n",
    "    else:\n",
    "        if(menu == 0):\n",
    "            return \"topic\"\n",
    "        elif(menu == 1):\n",
    "            return \"event\"\n",
    "        elif(menu == 2):\n",
    "            return \"call\"\n",
    "        elif(menu == 3):\n",
    "            return \"water\"\n",
    "        else:\n",
    "            return \"visitor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise dense output:\n",
      " [[ 1.          0.07715167  0.3678836   0.10101525  0.0805823   0.16903085]\n",
      " [ 0.07715167  1.          0.06622662  0.          0.17407766  0.        ]\n",
      " [ 0.3678836   0.06622662  1.          0.086711    0.13834289  0.2901905 ]\n",
      " [ 0.10101525  0.          0.086711    1.          0.11396058  0.11952286]\n",
      " [ 0.0805823   0.17407766  0.13834289  0.11396058  1.          0.09534626]\n",
      " [ 0.16903085  0.          0.2901905   0.11952286  0.09534626  1.        ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'other'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similarity(initial_features,textFeatures(processText(\"I have to leave the front of the room to call it.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVocabOpt():\n",
    "    vocabs = pd.read_csv('../vocab2.csv')\n",
    "    \n",
    "    topic = topicData()\n",
    "    event = eventData()\n",
    "    call = callData()\n",
    "    water = waterData()\n",
    "    visitor = visitorData()\n",
    "    \n",
    "    # Topic\n",
    "    topic_features = np.zeros(len(vocabs))\n",
    "    for i in range(len(topic)):\n",
    "        topic_features = topic_features + textFeatures(processText(topic[i]))\n",
    "\n",
    "    # Event\n",
    "    event_features = np.zeros(len(vocabs))\n",
    "    for i in range(len(event)):\n",
    "        event_features = event_features + textFeatures(processText(event[i]))\n",
    "    \n",
    "    # Call     \n",
    "    call_features = np.zeros(len(vocabs))\n",
    "    for i in range(len(call)):\n",
    "        call_features = call_features + textFeatures(processText(call[i]))\n",
    "    \n",
    "    # Water\n",
    "    water_features = np.zeros(len(vocabs))\n",
    "    for i in range(len(water)):\n",
    "        water_features = water_features + textFeatures(processText(water[i]))\n",
    "    \n",
    "    # Visitor\n",
    "    visitor_features = np.zeros(len(vocabs))\n",
    "    for i in range(len(visitor)):\n",
    "        visitor_features = visitor_features + textFeatures(processText(visitor[i]))\n",
    "    \n",
    "    all_words = topic_features + event_features + call_features + water_features + visitor_features\n",
    "    vocabs = vocabs[all_words >= 1]\n",
    "    vocabs['word'] = vocabs['0']\n",
    "    del vocabs['0']\n",
    "    \n",
    "    vocabs.to_csv('../vocab_opt.csv',index=False)\n",
    "    \n",
    "    return \"Create Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create Done!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createVocabOpt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------ END Train -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabListOpt():\n",
    "    vocabs = pd.read_csv('../vocab_opt.csv')\n",
    "    vocabs['number'] = vocabs.index + 1\n",
    "    return vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ask</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  number\n",
       "0      a       1\n",
       "1  activ       2\n",
       "2    and       3\n",
       "3    are       4\n",
       "4    ask       5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(getVocabListOpt().shape)\n",
    "getVocabListOpt().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "def processTextOpt(email_contents):\n",
    "    #load vocab\n",
    "    vocabList = getVocabListOpt()\n",
    "    \n",
    "    # ----- Process Email------\n",
    "    # Lower Case\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "    strip_all_html = re.compile('[>,<,<*>]') \n",
    "    email_contents = re.sub(strip_all_html, '', email_contents)\n",
    "    strip_all_html2 = re.compile('\\s') # \\s is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
    "    email_contents = re.sub(strip_all_html2, ' ', email_contents)\n",
    "    \n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    hundle_number = re.compile('\\d+')\n",
    "    email_contents = re.sub(hundle_number, 'number', email_contents)\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "    hundle_url = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    email_contents = re.sub(hundle_url, 'httpaddr', email_contents)\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # Look for strings with @ in the middle\n",
    "    hundle_email = re.compile('[\\w\\.-]+@[\\w\\.-]+')\n",
    "    email_contents = re.sub(hundle_email, 'emailaddr', email_contents)\n",
    "\n",
    "    # Handle $ sign\n",
    "    hundle_dollar = re.compile('[$]+')\n",
    "    email_contents = re.sub(hundle_dollar, 'dollar', email_contents)\n",
    "    \n",
    "    # Remove any non alphanumeric characters\n",
    "    non_cha_alp = re.compile(\"[^a-zA-Z0-9]+\")\n",
    "    email_contents = re.sub(non_cha_alp, ' ', email_contents)\n",
    "    \n",
    "    # ------- Stem words -------    \n",
    "    words = [stem(word) for word in email_contents.split(\" \") if len(word) > 0]\n",
    "    \n",
    "    # convert to number in vocab\n",
    "    word_indices = []\n",
    "    for w in words:\n",
    "        match = sum(vocabList['word'] == w)\n",
    "        if(match>0):\n",
    "            word_indices.append(vocabList.loc[(vocabList['word'] == w),'number'].astype(int).values[0])\n",
    "    \n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 39, 45, 35, 27, 6]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processTextOpt(\"Send someone to repair my bathroom.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textFeaturesOpt(word_indices):\n",
    "    vocabList = getVocabListOpt()\n",
    "    features = vocabList['number'].astype(int).isin(word_indices) + 0\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFeaturesOpt(processTextOpt(\"Send someone to repair my bathroom.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getInitialFeatureVectorOpt():\n",
    "    topic = topicData()\n",
    "    event = eventData()\n",
    "    call = callData()\n",
    "    water = waterData()\n",
    "    visitor = visitorData()\n",
    "    # Topic\n",
    "    topic_features = np.zeros(len(getVocabListOpt()))\n",
    "    for i in range(len(topic)):\n",
    "        topic_features = topic_features + textFeaturesOpt(processTextOpt(topic[i]))\n",
    "\n",
    "    # Event\n",
    "    event_features = np.zeros(len(getVocabListOpt()))\n",
    "    for i in range(len(event)):\n",
    "        event_features = event_features + textFeaturesOpt(processTextOpt(event[i]))\n",
    "    \n",
    "    # Call     \n",
    "    call_features = np.zeros(len(getVocabListOpt()))\n",
    "    for i in range(len(call)):\n",
    "        call_features = call_features + textFeaturesOpt(processTextOpt(call[i]))\n",
    "    \n",
    "    # Water\n",
    "    water_features = np.zeros(len(getVocabListOpt()))\n",
    "    for i in range(len(water)):\n",
    "        water_features = water_features + textFeaturesOpt(processTextOpt(water[i]))\n",
    "    \n",
    "    # Visitor\n",
    "    visitor_features = np.zeros(len(getVocabListOpt()))\n",
    "    for i in range(len(visitor)):\n",
    "        visitor_features = visitor_features + textFeaturesOpt(processTextOpt(visitor[i]))\n",
    "    \n",
    "    topic_features = (topic_features >= 1).astype(int)\n",
    "    event_features = (event_features >= 1).astype(int)\n",
    "    call_features = (call_features >= 1).astype(int)\n",
    "    water_features = (water_features >= 1).astype(int)\n",
    "    visitor_features = (visitor_features >= 1).astype(int)\n",
    "    \n",
    "    return np.array([topic_features, event_features, call_features, water_features, visitor_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_features_opt = getInitialFeatureVectorOpt()\n",
    "initial_features_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homecare\n",
    "- ผนังห้องนอนร้าวส่งช่างมาซ่อมหน่อย --> The bedroom is cracked and repaired.\n",
    "\n",
    "### Event / Activity\n",
    "- สอบถามกิจกรรมดูหนัง --> View Forum Posts\n",
    "\n",
    "### ค่าน้ำ\n",
    "- ค่าน้ำเดือนที่เเล้วเท่าไหร่ --> How much water monthly?\n",
    "\n",
    "### Call - Negative\n",
    "- ไฟดับนานมาก ดับมา 2 ชั่วโมงแล้ว มาซ่อมสักที --> The power went out for 2 hours and then came back.\n",
    "\n",
    "### สอบถามทั่วไป เกี่ยวกับโครงการ\n",
    "- สอบถามโครงการเซนทริกรัชโยธินครับ --> Ask for the Centric Ratchayothin project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise dense output:\n",
      " [[ 1.          0.07715167  0.3678836   0.10101525  0.0805823   0.11952286]\n",
      " [ 0.07715167  1.          0.06622662  0.          0.17407766  0.12909944]\n",
      " [ 0.3678836   0.06622662  1.          0.086711    0.13834289  0.20519567]\n",
      " [ 0.10101525  0.          0.086711    1.          0.11396058  0.16903085]\n",
      " [ 0.0805823   0.17407766  0.13834289  0.11396058  1.          0.67419986]\n",
      " [ 0.11952286  0.12909944  0.20519567  0.16903085  0.67419986  1.        ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'visitor'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similarity(initial_features_opt,textFeaturesOpt(processTextOpt(\"Ask for the Centric Ratchayothin project.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
